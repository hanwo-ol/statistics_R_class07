k-평균 군집분석 예제 코드와 결과에 대해 각 단계의 의미와 함수의 기능, 그리고 결과가 무엇을 말하는지 상세하게 설명해 드리겠습니다. 교수님의 이론수업을 잘 들으셔야 이해에 무리가 없으실 것 같습니다.

### 분석의 목표: 데이터의 숨겨진 그룹 찾기

**k-평균 군집분석(k-means clustering)**은 주어진 데이터들을 가장 비슷한 것들끼리 묶어 **k개의 그룹(군집, cluster)으로 나누는** 대표적인 비지도 학습(Unsupervised Learning) 알고리즘입니다. 여기서 "비지도"란, 데이터에 정답(label)이 미리 주어지지 않은 상태에서 데이터 자체의 구조나 패턴을 스스로 찾아낸다는 의미입니다.

이 분석의 목표는 **"2차원 평면에 흩어져 있는 50개의 점들 속에, 우리가 모르는 어떤 그룹 구조가 숨어있는가?"**를 k-평균 알고리즘을 통해 밝혀내는 것입니다.

---

### 단계별 코드 및 결과 상세 해설

#### 1. 모의실험 데이터 생성 및 시각화

```R
> # 데이터 생성
> set.seed(1)
> nc=2; n=50                  # 2개의 군집, 50개의 관측치
> x=matrix(rnorm(n*nc), ncol=nc) # 모의실험 자료 생성
> x[1:20, 1]=x[1:20, 1]+1
> x[21:n, 1]=x[21:n, 1]-2
>
> # 원본 데이터 시각화
> par(mfrow = c(1,1))
> plot(x, cex=2)
```

##### **함수 기능 설명**

*   `set.seed(1)`: R에서 난수(random number)를 생성할 때, 항상 동일한 순서의 난수가 나오도록 **시작점을 고정**하는 함수입니다. 이 코드를 실행하면 누가, 언제 실행하든 항상 똑같은 모의실험 데이터를 만들 수 있어 결과 재현에 필수적입니다.
*   `rnorm(n*nc)`: 평균이 0, 표준편차가 1인 표준 정규분포를 따르는 난수를 `n*nc`개, 즉 100개 생성합니다.
*   `matrix(..., ncol=nc)`: 100개의 난수를 2개의 열(`ncol=2`)을 가진 행렬로 만듭니다. 결과적으로 50행 2열의 데이터(`x`)가 생성됩니다.
*   `x[1:20, 1]=x[1:20, 1]+1`: 1번부터 20번까지 데이터의 첫 번째 열(x축 좌표) 값에 1을 더합니다. 이 점들을 오른쪽으로 1만큼 이동시키는 효과가 있습니다.
*   `x[21:n, 1]=x[21:n, 1]-2`: 21번부터 50번까지 데이터의 첫 번째 열(x축 좌표) 값에 2를 뺍니다. 이 점들을 왼쪽으로 2만큼 이동시키는 효과가 있습니다.
*   `plot(x, cex=2)`: 생성된 2차원 데이터 `x`를 산점도로 그립니다. `cex=2`는 점의 크기를 기본값보다 2배 크게 만듭니다.

##### **결과(데이터 생성 및 시각화) 해석**
이 과정을 통해 우리는 **의도적으로 2개의 그룹**을 만들었습니다.
*   **그룹 1**: 1~20번 데이터 (오른쪽으로 이동)
*   **그룹 2**: 21~50번 데이터 (왼쪽으로 이동)
`plot(x)`를 통해 시각화된 그래프를 보면, 사람의 눈으로도 명확하게 **오른쪽 그룹과 왼쪽 그룹, 2개의 덩어리(군집)가 존재함**을 알 수 있습니다. 이제 k-평균 알고리즘이 우리가 만든 이 정답을 얼마나 잘 찾아내는지 확인해 볼 것입니다.

---

#### 2. k=2로 군집분석 수행 및 결과 확인

```R
> # k=2로 군집분석
> km2 <- kmeans(x, 2)
> km2
```

##### **함수 기능 설명**

*   `kmeans(x, 2)`: k-평균 군집분석을 수행하는 핵심 함수입니다.
    *   `x`: 분석할 데이터입니다.
    *   `2`: 군집의 개수(k)를 **2개로 지정**합니다. 분석가는 데이터의 특성을 보고 이 k값을 사전에 정해주어야 합니다.
*   `km2`: `kmeans()` 함수의 모든 결과가 `km2`라는 객체에 저장됩니다.

##### **결과(`km2` 출력) 상세 해석**
```
K-means clustering with 2 clusters of sizes 19, 31
```
*   **해석**: k-평균 알고리즘이 50개의 데이터를 2개의 군집으로 나누었으며, 첫 번째 군집에는 19개의 점이, 두 번째 군집에는 31개의 점이 포함되었습니다.

```
Cluster means:
       [,1]         [,2]
1  1.317115  0.311508740
2 -1.935573 -0.001688496
```
*   **의미**: 각 군집의 **중심(centroid)** 좌표를 의미합니다. k-평균 알고리즘은 이 중심점과 각 데이터 점 사이의 거리를 기반으로 군집을 형성합니다.
*   **해석**:
    *   군집 1의 중심은 (1.317, 0.312)로, **오른쪽**에 위치합니다.
    *   군집 2의 중심은 (-1.936, -0.002)로, **왼쪽**에 위치합니다.
    *   이는 알고리즘이 우리가 의도한 두 그룹의 중심을 정확히 찾아냈음을 보여줍니다.

```
Clustering vector:
 [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 ...
```
*   **의미**: 50개의 각 데이터 점이 몇 번 군집에 할당되었는지를 보여주는 벡터입니다.
*   **해석**:
    *   1번부터 20번 데이터는 대부분 `1`번 군집에 할당되었지만, 14번 데이터는 `2`번 군집으로 잘못 분류되었습니다.
    *   21번부터 50번 데이터는 모두 `2`번 군집에 잘 할당되었습니다.
    *   **결론**: k=2로 설정했을 때, 알고리즘은 우리가 의도한 구조를 거의 완벽하게(1개 제외) 찾아냈습니다.

```
Within cluster sum of squares by cluster:
[1] 34.36424 38.51950
 (between_SS / total_SS =  63.3 %)
```
*   **Within cluster sum of squares (WSS)**: **군집 내 응집도**를 나타내는 지표입니다. 각 군집 내부에서, 군집 중심과 소속된 점들 간의 거리(오차) 제곱의 합입니다. **이 값이 작을수록 군집 내의 점들이 중심에 잘 뭉쳐있다는 의미**입니다.
*   **(between_SS / total_SS)**: **군집 간 분리도**를 나타내는 지표입니다. 전체 데이터의 변동(total_SS) 중에서, 군집 간의 차이로 설명되는 변동(between_SS)의 비율입니다. **이 값이 클수록 군집들이 서로 명확하게 잘 구분된다는 의미**입니다. 여기서는 전체 변동의 63.3%가 군집 간 차이로 설명됩니다.

<img width="1308" height="751" alt="image" src="https://github.com/user-attachments/assets/5c76285d-87da-458e-b8ad-849a168504ef" />

##### **시각화 결과(왼쪽) (`plot(x, pch=km2$cluster, ...)`**

*   **해석**: 이 그래프는 군집 분석 결과를 시각화한 것입니다. 각 점의 색상과 모양(`col=km2$cluster`, `pch=km2$cluster`)으로 소속된 군집을 표현합니다. 사람의 눈으로 봤던 원래 데이터의 구조와 k-평균 분석 결과가 거의 일치함을 한눈에 확인할 수 있습니다.

---

#### 3. k=3으로 군집분석 수행 및 결과 확인

```R
> # k=3으로 군집분석
> km3 <- kmeans(x, 3)
> km3
```

##### **함수 기능 설명**
*   `kmeans(x, 3)`: 이번에는 **군집의 개수(k)를 3개로 지정**하여 분석을 수행합니다. 데이터의 실제 구조는 2개의 그룹이지만, 일부러 잘못된 k값을 주었을 때 어떤 결과가 나오는지 확인하기 위함입니다.

##### **결과(`km3` 출력) 상세 해석**
```
K-means clustering with 3 clusters of sizes 31, 14, 5
```
*   **해석**: 데이터를 31개, 14개, 5개짜리 3개의 군집으로 나누었습니다.

```
Cluster means:
       [,1]         [,2]
1 -1.935573 -0.001688496
2  1.247616 -0.252467274
3  1.511712  1.890641579
```
*   **해석**: 군집 1은 왼쪽에, 군집 2와 3은 오른쪽에 중심이 위치합니다. 즉, 원래 하나의 덩어리였던 오른쪽 그룹을 알고리즘이 억지로 2개로 쪼갠 것입니다.

<img width="1308" height="751" alt="image" src="https://github.com/user-attachments/assets/147c1d2c-714e-4dc5-95cf-592a90c5aa72" />


```
Within cluster sum of squares by cluster:
[1] 38.519505 13.445706  3.740301
 (between_SS / total_SS =  72.0 %)
```
*   **해석**:
    *   **(between_SS / total_SS) = 72.0 %**: 이 값은 k=2일 때(63.3%)보다 **증가했습니다.**
    *   **주의할 점**: k값이 증가하면 군집이 더 잘게 쪼개지므로, 군집 내 응집도(WSS)는 항상 감소하고 군집 간 분리도(between_SS/total_SS)는 항상 증가하는 경향이 있습니다. 따라서 **이 수치가 무조건 높다고 해서 더 좋은 모델인 것은 아닙니다.** 실제 데이터의 구조를 잘 반영하는 "적절한" k를 찾는 것이 중요하며, 이를 위해 엘보우 방법(Elbow method) 등의 기법을 사용합니다.
    *   이 예제에서는 우리가 정답(k=2)을 알고 있으므로, k=3은 데이터를 과적합(overfitting)하여 불필요하게 쪼갠, 좋지 않은 모델임을 알 수 있습니다.

### 종합 결론

1.  **k-평균 군집분석의 성공**: 우리가 의도적으로 만든 2개의 그룹 구조를 k-평균 알고리즘(`k=2` 설정)이 매우 정확하게 찾아냈습니다. 이는 데이터 내에 숨겨진 그룹 구조를 발견하는 데 k-평균 알고리즘이 효과적임을 보여줍니다.
2.  **k값 설정의 중요성**: 분석가는 데이터에 대한 이해를 바탕으로 적절한 군집의 개수(k)를 지정해야 합니다. 잘못된 k값(예: `k=3`)을 설정하면, 통계 지표상으로는 더 좋아 보일 수 있지만 실제로는 의미 없는 군집으로 데이터를 쪼개는 결과를 낳을 수 있습니다.
3.  **결과 해석**: `kmeans` 함수의 결과 객체는 군집의 중심 좌표, 각 데이터의 소속 군집, 군집의 응집도/분리도 등 군집의 특성을 파악하는 데 유용한 다양한 정보를 제공합니다.
